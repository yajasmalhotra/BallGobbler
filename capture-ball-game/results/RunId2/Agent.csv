Steps,Policy/Entropy,Policy/Extrinsic Value Estimate,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Losses/Pretraining Loss,Is Training
50000,4.1312485,1.8573833,1230.5,669.8027777936724,669.8027777936724,167.01744,0.025570264,0.00029922332,0.1997411,0.0004987314,0.92989516,1.0
100000,3.8848443,6.1074615,1202.3809523809523,887.4333320572263,887.4333320572263,281.92792,0.024391513,0.000297834,0.19927797,0.00049646216,0.8117298,1.0
150000,3.4861934,11.244923,1202.35,1091.1949999094008,1091.1949999094008,413.4864,0.024173308,0.00029629335,0.19876447,0.00049394584,0.7799947,1.0
200000,3.2825851,17.117496,1202.2727272727273,1281.1181824857538,1281.1181824857538,506.8732,0.026565041,0.0002947543,0.19825141,0.000491432,0.7708484,1.0
